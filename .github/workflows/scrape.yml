name: Daily Scraping Task

on:
  schedule:
    # Ejecutar diariamente a las 12:00 AM UTC
    - cron: '0 0 * * *'  # Configura la hora de ejecución en formato cron (UTC)
  workflow_dispatch:  # También se puede ejecutar manualmente desde GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium beautifulsoup4 pandas

    - name: Run scraper
      run: |
        python scrape.py

    - name: Commit and push new CSV to repository
      run: |
        # Obtener la fecha actual
        DATE=$(date +'%Y-%m-%d')
        # Crear directorio para la fecha
        mkdir -p "data/$DATE-SBS"
        # Mover el CSV generado al directorio correspondiente
        mv tasas_sbs.csv "data/$DATE-SBS/tasas_sbs.csv"
        # Agregar los cambios a Git
        git add "data/$DATE-SBS/tasas_sbs.csv"
        git commit -m "Add CSV for $DATE"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Token para autenticación
